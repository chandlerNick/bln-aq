{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5a039a",
   "metadata": {},
   "source": [
    "get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5d07b",
   "metadata": {},
   "source": [
    "pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c026440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NO2 data from 01.01.2024 00 to 31.01.2024 00\n",
      "Downloading NO2 data from 31.01.2024 01 to 01.03.2024 01\n",
      "Downloading NO2 data from 01.03.2024 02 to 31.03.2024 02\n",
      "Downloading NO2 data from 31.03.2024 03 to 30.04.2024 03\n",
      "Downloading NO2 data from 30.04.2024 04 to 30.05.2024 04\n",
      "Downloading NO2 data from 30.05.2024 05 to 29.06.2024 05\n",
      "Downloading NO2 data from 29.06.2024 06 to 29.07.2024 06\n",
      "Downloading NO2 data from 29.07.2024 07 to 28.08.2024 07\n",
      "Downloading NO2 data from 28.08.2024 08 to 27.09.2024 08\n",
      "Downloading NO2 data from 27.09.2024 09 to 27.10.2024 09\n",
      "Downloading NO2 data from 27.10.2024 10 to 26.11.2024 10\n",
      "Downloading NO2 data from 26.11.2024 11 to 26.12.2024 11\n",
      "Downloading NO2 data from 26.12.2024 12 to 31.12.2024 23\n",
      "Downloading PM10 data from 01.01.2024 00 to 31.01.2024 00\n",
      "Downloading PM10 data from 31.01.2024 01 to 01.03.2024 01\n",
      "Downloading PM10 data from 01.03.2024 02 to 31.03.2024 02\n",
      "Downloading PM10 data from 31.03.2024 03 to 30.04.2024 03\n",
      "Downloading PM10 data from 30.04.2024 04 to 30.05.2024 04\n",
      "Downloading PM10 data from 30.05.2024 05 to 29.06.2024 05\n",
      "Downloading PM10 data from 29.06.2024 06 to 29.07.2024 06\n",
      "Downloading PM10 data from 29.07.2024 07 to 28.08.2024 07\n",
      "Downloading PM10 data from 28.08.2024 08 to 27.09.2024 08\n",
      "Downloading PM10 data from 27.09.2024 09 to 27.10.2024 09\n",
      "Downloading PM10 data from 27.10.2024 10 to 26.11.2024 10\n",
      "Downloading PM10 data from 26.11.2024 11 to 26.12.2024 11\n",
      "Downloading PM10 data from 26.12.2024 12 to 31.12.2024 23\n",
      "Downloading O3 data from 01.01.2024 00 to 31.01.2024 00\n",
      "Downloading O3 data from 31.01.2024 01 to 01.03.2024 01\n",
      "Downloading O3 data from 01.03.2024 02 to 31.03.2024 02\n",
      "Downloading O3 data from 31.03.2024 03 to 30.04.2024 03\n",
      "Downloading O3 data from 30.04.2024 04 to 30.05.2024 04\n",
      "Downloading O3 data from 30.05.2024 05 to 29.06.2024 05\n",
      "Downloading O3 data from 29.06.2024 06 to 29.07.2024 06\n",
      "Downloading O3 data from 29.07.2024 07 to 28.08.2024 07\n",
      "Downloading O3 data from 28.08.2024 08 to 27.09.2024 08\n",
      "Downloading O3 data from 27.09.2024 09 to 27.10.2024 09\n",
      "Downloading O3 data from 27.10.2024 10 to 26.11.2024 10\n",
      "Downloading O3 data from 26.11.2024 11 to 26.12.2024 11\n",
      "Downloading O3 data from 26.12.2024 12 to 31.12.2024 23\n",
      "                  time      station  value measurement\n",
      "0  2024-01-01 00:00:00  010 Wedding   16.0         no2\n",
      "1  2024-01-01 01:00:00  010 Wedding   42.0         no2\n",
      "2  2024-01-01 02:00:00  010 Wedding   42.0         no2\n",
      "3  2024-01-01 03:00:00  010 Wedding   30.0         no2\n",
      "4  2024-01-01 04:00:00  010 Wedding   23.0         no2\n",
      "5  2024-01-01 05:00:00  010 Wedding   19.0         no2\n",
      "6  2024-01-01 06:00:00  010 Wedding   19.0         no2\n",
      "7  2024-01-01 07:00:00  010 Wedding   15.0         no2\n",
      "8  2024-01-01 08:00:00  010 Wedding   12.0         no2\n",
      "9  2024-01-01 09:00:00  010 Wedding   12.0         no2\n",
      "10 2024-01-01 10:00:00  010 Wedding   10.0         no2\n",
      "11 2024-01-01 11:00:00  010 Wedding    9.0         no2\n",
      "12 2024-01-01 12:00:00  010 Wedding   10.0         no2\n",
      "13 2024-01-01 13:00:00  010 Wedding   11.0         no2\n",
      "14 2024-01-01 14:00:00  010 Wedding   10.0         no2\n",
      "15 2024-01-01 15:00:00  010 Wedding   12.0         no2\n",
      "16 2024-01-01 16:00:00  010 Wedding   15.0         no2\n",
      "17 2024-01-01 17:00:00  010 Wedding   11.0         no2\n",
      "18 2024-01-01 18:00:00  010 Wedding   11.0         no2\n",
      "19 2024-01-01 19:00:00  010 Wedding   13.0         no2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Website link/datasheet -> loaction of stations findable from here too: https://luftdaten.berlin.de/pollution/\n",
    "\n",
    "\n",
    "def clean_station_data(df: pd.DataFrame, measurement: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans a station dataframe:\n",
    "    - Drops first three metadata rows\n",
    "    - Converts from wide to long format\n",
    "    - Parses measurement time\n",
    "    - Adds a 'measurement' column\n",
    "    \"\"\"\n",
    "    # Drop first three rows\n",
    "    df = df.iloc[3:].copy()\n",
    "    \n",
    "    # Rename columns: first column is 'time', others stay as station names\n",
    "    df = df.rename(columns={df.columns[0]: 'time'})\n",
    "    \n",
    "    # Melt the dataframe to long format\n",
    "    df_long = df.melt(id_vars='time', var_name='station', value_name='value')\n",
    "    \n",
    "    # Parse time column\n",
    "    df_long['time'] = pd.to_datetime(df_long['time'], format='%d.%m.%Y %H:%M')\n",
    "    \n",
    "    # Add measurement column\n",
    "    df_long['measurement'] = measurement\n",
    "\n",
    "    # Convert values to numeric (in case there are missing or non-numeric entries)\n",
    "    df_long['value'] = pd.to_numeric(df_long['value'], errors='coerce')\n",
    "    \n",
    "\n",
    "    \n",
    "    return df_long\n",
    "\n",
    "\n",
    "def download_and_clean(pollutant: str, start: datetime, end: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads and cleans data for a given pollutant from Berlin Luftdaten.\n",
    "    \"\"\"\n",
    "    base_url = f\"https://luftdaten.berlin.de/core/{pollutant}.csv?stationgroup=all&period=1h&timespan=custom&start[date]={{start_date}}&start[hour]={{start_hour}}&end[date]={{end_date}}&end[hour]={{end_hour}}\"\n",
    "    \n",
    "    delta = timedelta(days=30)\n",
    "    all_data = []\n",
    "\n",
    "    current_start = start\n",
    "    while current_start < end:\n",
    "        current_end = min(current_start + delta, end)\n",
    "        \n",
    "        # Format dates\n",
    "        start_date = current_start.strftime(\"%d.%m.%Y\")\n",
    "        start_hour = current_start.strftime(\"%H\")\n",
    "        end_date = current_end.strftime(\"%d.%m.%Y\")\n",
    "        end_hour = current_end.strftime(\"%H\")\n",
    "        \n",
    "        # Build URL\n",
    "        url = base_url.format(start_date=start_date, start_hour=start_hour,\n",
    "                              end_date=end_date, end_hour=end_hour)\n",
    "        \n",
    "        print(f\"Downloading {pollutant.upper()} data from {start_date} {start_hour} to {end_date} {end_hour}\")\n",
    "        \n",
    "        # Download CSV\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            df = pd.read_csv(StringIO(response.text), sep=\";\")\n",
    "            cleaned = clean_station_data(df, pollutant)\n",
    "            all_data.append(cleaned)\n",
    "        else:\n",
    "            print(f\"Error downloading {pollutant}: {response.status_code}\")\n",
    "        \n",
    "        current_start = current_end + timedelta(hours=1)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['time', 'station', 'value', 'measurement'])\n",
    "\n",
    "\n",
    "# Define period\n",
    "start = datetime(2024, 1, 1, 0)\n",
    "end = datetime(2024, 12, 31, 23)\n",
    "\n",
    "# Download & clean each pollutant\n",
    "pollutants = ['no2', 'pm10', 'o3']\n",
    "dfs = [download_and_clean(p, start, end) for p in pollutants]\n",
    "\n",
    "# Combine into one long dataframe\n",
    "full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(full_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58945b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"./data/2024-pollutants.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17080b8",
   "metadata": {},
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66ea738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wetterdienst.provider.dwd.observation import DwdObservationRequest\n",
    "import datetime as dt\n",
    "\n",
    "# REFERENCE! https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/\n",
    "# API version 0.113.0\n",
    "# Berlin station IDs\n",
    "berlin_stations = (\"00399\", \"00400\", \"00403\", \"00410\", \"00420\", \"00424\", \"00427\", \"00430\", \"00433\")\n",
    "\n",
    "# Map of parameters to dataset codes\n",
    "parameters = [\n",
    "    (\"hourly\", \"temperature_air\"),\n",
    "    (\"hourly\", \"pressure\"),  # Air pressure\n",
    "    (\"hourly\", \"moisture\"),  # Humidity\n",
    "    (\"hourly\", \"precipitation\"),  # precipitation height\n",
    "    (\"hourly\", \"wind_synop\")\n",
    "]\n",
    "\n",
    "request = DwdObservationRequest(\n",
    "    parameters = parameters,\n",
    "    start_date=\"2024-01-01\",\n",
    "    end_date=\"2024-12-31\"\n",
    ")\n",
    "stations = request.filter_by_station_id(station_id=berlin_stations)\n",
    "df = stations.values.all().df.drop_nulls()\n",
    "df\n",
    "\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b39ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "\n",
    "df.columns = cols\n",
    "\n",
    "df.to_csv(\"./data/2024-weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8490d8f3",
   "metadata": {},
   "source": [
    "Citizen Science Data- Done on cluster.\n",
    "\n",
    "https://archive.sensor.community/csv_per_month/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f797fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️  Downloading https://archive.sensor.community/csv_per_month/2024-01/2024-01_sds011.zip ...\n",
      "💾 Saved to data/citsci/2024-01_sds011.zip\n",
      "⬇️  Downloading https://archive.sensor.community/csv_per_month/2024-02/2024-02_sds011.zip ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dest, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m):\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:\n\u001b[1;32m     32\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/response.py:1091\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1091\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1094\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 980\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/response.py:904\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    901\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/response.py:887\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURATION\n",
    "# ==============================\n",
    "BASE_URL = \"https://archive.sensor.community/csv_per_month\"\n",
    "DATA_DIR = Path(\"data/citsci\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SENSOR_TYPE = \"sds011\"\n",
    "YEAR = 2024\n",
    "\n",
    "# ==============================\n",
    "# DOWNLOAD LOOP\n",
    "# ==============================\n",
    "for month in range(1, 13):\n",
    "    month_str = f\"{month:02d}\"\n",
    "    url = f\"{BASE_URL}/{YEAR}-{month_str}/{YEAR}-{month_str}_{SENSOR_TYPE}.zip\"\n",
    "    dest = DATA_DIR / f\"{YEAR}-{month_str}_{SENSOR_TYPE}.zip\"\n",
    "\n",
    "    if dest.exists():\n",
    "        print(f\"✅ Already downloaded: {dest.name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"⬇️  Downloading {url} ...\")\n",
    "    try:\n",
    "        with requests.get(url, stream=True, timeout=60) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(dest, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        print(f\"💾 Saved to {dest}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to download {url}: {e}\")\n",
    "\n",
    "print(\"✅ All downloads complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
