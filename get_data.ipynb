{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5a039a",
   "metadata": {},
   "source": [
    "get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5d07b",
   "metadata": {},
   "source": [
    "pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NO2 data from 01.01.2024 00 to 31.01.2024 00\n",
      "Downloading NO2 data from 31.01.2024 01 to 01.03.2024 01\n",
      "Downloading NO2 data from 01.03.2024 02 to 31.03.2024 02\n",
      "Downloading NO2 data from 31.03.2024 03 to 30.04.2024 03\n",
      "Downloading NO2 data from 30.04.2024 04 to 30.05.2024 04\n",
      "Downloading NO2 data from 30.05.2024 05 to 29.06.2024 05\n",
      "Downloading NO2 data from 29.06.2024 06 to 29.07.2024 06\n",
      "Downloading NO2 data from 29.07.2024 07 to 28.08.2024 07\n",
      "Downloading NO2 data from 28.08.2024 08 to 27.09.2024 08\n",
      "Downloading NO2 data from 27.09.2024 09 to 27.10.2024 09\n",
      "Downloading NO2 data from 27.10.2024 10 to 26.11.2024 10\n",
      "Downloading NO2 data from 26.11.2024 11 to 26.12.2024 11\n",
      "Downloading NO2 data from 26.12.2024 12 to 31.12.2024 23\n",
      "Downloading PM10 data from 01.01.2024 00 to 31.01.2024 00\n",
      "Downloading PM10 data from 31.01.2024 01 to 01.03.2024 01\n",
      "Downloading PM10 data from 01.03.2024 02 to 31.03.2024 02\n",
      "Downloading PM10 data from 31.03.2024 03 to 30.04.2024 03\n",
      "Downloading PM10 data from 30.04.2024 04 to 30.05.2024 04\n",
      "Downloading PM10 data from 30.05.2024 05 to 29.06.2024 05\n",
      "Downloading PM10 data from 29.06.2024 06 to 29.07.2024 06\n",
      "Downloading PM10 data from 29.07.2024 07 to 28.08.2024 07\n",
      "Downloading PM10 data from 28.08.2024 08 to 27.09.2024 08\n",
      "Downloading PM10 data from 27.09.2024 09 to 27.10.2024 09\n",
      "Downloading PM10 data from 27.10.2024 10 to 26.11.2024 10\n",
      "Downloading PM10 data from 26.11.2024 11 to 26.12.2024 11\n",
      "Downloading PM10 data from 26.12.2024 12 to 31.12.2024 23\n",
      "Downloading O3 data from 01.01.2024 00 to 31.01.2024 00\n",
      "Downloading O3 data from 31.01.2024 01 to 01.03.2024 01\n",
      "Downloading O3 data from 01.03.2024 02 to 31.03.2024 02\n",
      "Downloading O3 data from 31.03.2024 03 to 30.04.2024 03\n",
      "Downloading O3 data from 30.04.2024 04 to 30.05.2024 04\n",
      "Downloading O3 data from 30.05.2024 05 to 29.06.2024 05\n",
      "Downloading O3 data from 29.06.2024 06 to 29.07.2024 06\n",
      "Downloading O3 data from 29.07.2024 07 to 28.08.2024 07\n",
      "Downloading O3 data from 28.08.2024 08 to 27.09.2024 08\n",
      "Downloading O3 data from 27.09.2024 09 to 27.10.2024 09\n",
      "Downloading O3 data from 27.10.2024 10 to 26.11.2024 10\n",
      "Downloading O3 data from 26.11.2024 11 to 26.12.2024 11\n",
      "Downloading O3 data from 26.12.2024 12 to 31.12.2024 23\n",
      "                  time      station  value measurement\n",
      "0  2024-01-01 00:00:00  010 Wedding   16.0         no2\n",
      "1  2024-01-01 01:00:00  010 Wedding   42.0         no2\n",
      "2  2024-01-01 02:00:00  010 Wedding   42.0         no2\n",
      "3  2024-01-01 03:00:00  010 Wedding   30.0         no2\n",
      "4  2024-01-01 04:00:00  010 Wedding   23.0         no2\n",
      "5  2024-01-01 05:00:00  010 Wedding   19.0         no2\n",
      "6  2024-01-01 06:00:00  010 Wedding   19.0         no2\n",
      "7  2024-01-01 07:00:00  010 Wedding   15.0         no2\n",
      "8  2024-01-01 08:00:00  010 Wedding   12.0         no2\n",
      "9  2024-01-01 09:00:00  010 Wedding   12.0         no2\n",
      "10 2024-01-01 10:00:00  010 Wedding   10.0         no2\n",
      "11 2024-01-01 11:00:00  010 Wedding    9.0         no2\n",
      "12 2024-01-01 12:00:00  010 Wedding   10.0         no2\n",
      "13 2024-01-01 13:00:00  010 Wedding   11.0         no2\n",
      "14 2024-01-01 14:00:00  010 Wedding   10.0         no2\n",
      "15 2024-01-01 15:00:00  010 Wedding   12.0         no2\n",
      "16 2024-01-01 16:00:00  010 Wedding   15.0         no2\n",
      "17 2024-01-01 17:00:00  010 Wedding   11.0         no2\n",
      "18 2024-01-01 18:00:00  010 Wedding   11.0         no2\n",
      "19 2024-01-01 19:00:00  010 Wedding   13.0         no2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Website link/datasheet -> loaction of stations findable from here too: https://luftdaten.berlin.de/pollution/\n",
    "\n",
    "\n",
    "def clean_station_data(df: pd.DataFrame, measurement: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans a station dataframe:\n",
    "    - Drops first three metadata rows\n",
    "    - Converts from wide to long format\n",
    "    - Parses measurement time\n",
    "    - Adds a 'measurement' column\n",
    "    \"\"\"\n",
    "    # Drop first three rows\n",
    "    df = df.iloc[3:].copy()\n",
    "    \n",
    "    # Rename columns: first column is 'time', others stay as station names\n",
    "    df = df.rename(columns={df.columns[0]: 'time'})\n",
    "    \n",
    "    # Melt the dataframe to long format\n",
    "    df_long = df.melt(id_vars='time', var_name='station', value_name='value')\n",
    "    \n",
    "    # Parse time column\n",
    "    df_long['time'] = pd.to_datetime(df_long['time'], format='%d.%m.%Y %H:%M')\n",
    "    \n",
    "    # Add measurement column\n",
    "    df_long['measurement'] = measurement\n",
    "\n",
    "    # Convert values to numeric (in case there are missing or non-numeric entries)\n",
    "    df_long['value'] = pd.to_numeric(df_long['value'], errors='coerce')\n",
    "    \n",
    "\n",
    "    \n",
    "    return df_long\n",
    "\n",
    "\n",
    "def download_and_clean(pollutant: str, start: datetime, end: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads and cleans data for a given pollutant from Berlin Luftdaten.\n",
    "    \"\"\"\n",
    "    base_url = f\"https://luftdaten.berlin.de/core/{pollutant}.csv?stationgroup=all&period=1h&timespan=custom&start[date]={{start_date}}&start[hour]={{start_hour}}&end[date]={{end_date}}&end[hour]={{end_hour}}\"\n",
    "    \n",
    "    delta = timedelta(days=30)\n",
    "    all_data = []\n",
    "\n",
    "    current_start = start\n",
    "    while current_start < end:\n",
    "        current_end = min(current_start + delta, end)\n",
    "        \n",
    "        # Format dates\n",
    "        start_date = current_start.strftime(\"%d.%m.%Y\")\n",
    "        start_hour = current_start.strftime(\"%H\")\n",
    "        end_date = current_end.strftime(\"%d.%m.%Y\")\n",
    "        end_hour = current_end.strftime(\"%H\")\n",
    "        \n",
    "        # Build URL\n",
    "        url = base_url.format(start_date=start_date, start_hour=start_hour,\n",
    "                              end_date=end_date, end_hour=end_hour)\n",
    "        \n",
    "        print(f\"Downloading {pollutant.upper()} data from {start_date} {start_hour} to {end_date} {end_hour}\")\n",
    "        \n",
    "        # Download CSV\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            df = pd.read_csv(StringIO(response.text), sep=\";\")\n",
    "            cleaned = clean_station_data(df, pollutant)\n",
    "            all_data.append(cleaned)\n",
    "        else:\n",
    "            print(f\"Error downloading {pollutant}: {response.status_code}\")\n",
    "        \n",
    "        current_start = current_end + timedelta(hours=1)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['time', 'station', 'value', 'measurement'])\n",
    "\n",
    "\n",
    "# Define period\n",
    "start = datetime(2024, 1, 1, 0)\n",
    "end = datetime(2024, 12, 31, 23)\n",
    "\n",
    "# Download & clean each pollutant\n",
    "pollutants = ['no2', 'pm10', 'o3']\n",
    "dfs = [download_and_clean(p, start, end) for p in pollutants]\n",
    "\n",
    "# Combine into one long dataframe\n",
    "full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(full_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58945b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"./data/2024-pollutants.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17080b8",
   "metadata": {},
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b66ea738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wetterdienst.provider.dwd.observation import DwdObservationRequest\n",
    "import datetime as dt\n",
    "\n",
    "# REFERENCE! https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/\n",
    "# API version 0.113.0\n",
    "# Berlin station IDs\n",
    "berlin_stations = (\"00399\", \"00400\", \"00403\", \"00410\", \"00420\", \"00424\", \"00427\", \"00430\", \"00433\")\n",
    "\n",
    "# Map of parameters to dataset codes\n",
    "parameters = [\n",
    "    (\"hourly\", \"temperature_air\"),\n",
    "    (\"hourly\", \"pressure\"),  # Air pressure\n",
    "    (\"hourly\", \"moisture\"),  # Humidity\n",
    "    (\"hourly\", \"precipitation\"),  # precipitation height\n",
    "    (\"hourly\", \"wind_synop\")\n",
    "]\n",
    "\n",
    "request = DwdObservationRequest(\n",
    "    parameters = parameters,\n",
    "    start_date=\"2024-01-01\",\n",
    "    end_date=\"2024-12-31\"\n",
    ")\n",
    "stations = request.filter_by_station_id(station_id=berlin_stations)\n",
    "df = stations.values.all().df.drop_nulls()\n",
    "df\n",
    "\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5b39ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "\n",
    "df.columns = cols\n",
    "\n",
    "df.to_csv(\"./data/2024-weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d80799",
   "metadata": {},
   "source": [
    "traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad0a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wetter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
